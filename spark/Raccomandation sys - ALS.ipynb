{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MASTER=local[4]\n"
     ]
    }
   ],
   "source": [
    "%env MASTER=local[4]\n",
    "#SparkContext.setSystemProperty('spark.executor.memory', '8g')\n",
    "sc = SparkContext(\"local\", \"spark session ratings\")\n",
    "spark = (SparkSession.builder\n",
    "            .master(\"local\")\n",
    "            .appName(\"spark session ratings\")\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir('~/checkpoints')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp /data/movie_dataset/ratings.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (sc.textFile(\"ratings.csv\")\n",
    "         .filter(lambda s: not s.startswith(\"userId\")) # to ignore header\n",
    "        )\n",
    "parts = lines.map(lambda row: row.split(\",\"))\n",
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), \n",
    "                                     movieId=int(p[1]),\n",
    "                                     rating=float(p[2])\n",
    "                                    )\n",
    "                      )#.filter(lambda r: r.movieId in top_movies)\n",
    "ratings = spark.createDataFrame(ratingsRDD)\n",
    "#ratings.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_movies = ratings.groupby(\"movieId\").count()\n",
    "top_movies = top_movies.sort(F.col(\"count\").desc()).select(\"movieId\").limit(9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.filter(ratings.movieId.isin(top_movies.movieId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = ratings.randomSplit([0.8, 0.2], 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Null model as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(metricName=\"r2\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_votes = training.groupby(\"movieId\").avg(\"rating\").withColumnRenamed(\"avg(rating)\",\"prediction\")\n",
    "test_null_model = avg_votes.join(test,test.movieId==avg_votes.movieId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST r^2 base = 0.18257645067228345\n"
     ]
    }
   ],
   "source": [
    "r2_base = evaluator.evaluate(test_null_model)\n",
    "print(\"TEST r^2 base = \" +str(r2_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5496725622008477"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "avg = 2.5\n",
    "test_null_bin = test_null_model.rdd.map(lambda r: \n",
    "                                        (1. if r.prediction >= avg else 0., 1. if r.rating >= avg else 0.)\n",
    "                                       )\n",
    "\n",
    "bin_clf =  BinaryClassificationMetrics(test_null_bin)\n",
    "bin_clf.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    als = ALS(maxIter=25, regParam=0.15, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "              coldStartStrategy=\"drop\", seed=46)\n",
    "    model = als.fit(training)\n",
    "    model.write().overwrite().save(\"als.model\")\n",
    "else:\n",
    "    model = ALSModel.load(\"als.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.transform(test).na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST r^2 = 0.37501610720436007\n"
     ]
    }
   ],
   "source": [
    "r2_als = evaluator.evaluate(test_predictions)\n",
    "print(\"TEST r^2 = \" + str(r2_als))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6732428900128344"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "avg = 2.5\n",
    "test_predictions_bin = test_predictions.rdd.map(lambda r: (1. if r.prediction>=avg else 0., 1. if r.rating >= avg else 0.))\n",
    "\n",
    "bin_clf =  BinaryClassificationMetrics(test_predictions_bin)\n",
    "bin_clf.areaUnderROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions.sort(\"userId\").write.format(\"csv\").save(\"test_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+----------+\n",
      "|userId|movieId|rating|prediction|\n",
      "+------+-------+------+----------+\n",
      "|    11|  55363|   3.0| 3.0163019|\n",
      "|    11|  33437|   3.0| 3.0601606|\n",
      "|    11|  58559|   4.5|  3.563614|\n",
      "|    11|  57368|   3.5| 2.8807693|\n",
      "|    11|  55247|   4.5| 3.3111665|\n",
      "|    11|  53921|   3.5|  2.848623|\n",
      "|    11|     47|   3.5| 3.4663193|\n",
      "|    11|   7347|   3.5|  2.870282|\n",
      "|    11|  48774|   3.5| 3.2386696|\n",
      "|    11|   2054|   2.5|  2.443082|\n",
      "|    11|  53322|   4.0| 3.1258006|\n",
      "|    11|  49272|   3.5|  3.322027|\n",
      "|    11|  60126|   3.0| 2.8522007|\n",
      "|    11|  56633|   2.5| 2.9587643|\n",
      "|    11|  52973|   3.5| 3.0321949|\n",
      "|    11|  49130|   3.5|    3.0962|\n",
      "|    11|  51935|   4.0|  3.187418|\n",
      "|    11|  55729|   2.0| 2.9732869|\n",
      "|    11|  44555|   4.0|   3.48112|\n",
      "|    11|  61132|   3.5| 2.8985257|\n",
      "+------+-------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions.filter(\"userId == 11\").show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
