{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import helper as h\n",
    "import pymongo\n",
    "\n",
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS, ALSModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mv = 10000\n",
    "client = pymongo.MongoClient('mongodb://127.0.0.1:27017/')\n",
    "db = client['movie_dataset']\n",
    "top_movies = db['top_movies'].find({'$limit': top_mv})\n",
    "top_movies = [ m for m in top_movies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(\"local\", \"spark session ratings\")\n",
    "spark = (SparkSession.builder\n",
    "            .master(\"local\")\n",
    "            .appName(\"spark session ratings\")\n",
    "            .enableHiveSupport()\n",
    "            .getOrCreate()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (sc.textFile(\"ratings.csv\")\n",
    "         .filter(lambda s: not s.startswith(\"userId\")) # to ignore header\n",
    "        )\n",
    "parts = lines.map(lambda row: row.split(\",\"))\n",
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), \n",
    "                                     movieId=int(p[1]),\n",
    "                                     rating=float(p[2])/5, # => [0,1]\n",
    "                                     timestamp=int(p[3])\n",
    "                                    )\n",
    "                      )#.filter(lambda r: r.movieId in top_movies)\n",
    "ratings = spark.createDataFrame(ratingsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training, test) = ratings.randomSplit([0.8, 0.2], 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN = not False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN:\n",
    "    # Build the recommendation model using ALS on the training data\n",
    "    # Note we set cold start strategy to 'drop' to ensure we don't get NaN evaluation metrics\n",
    "    als = ALS(maxIter=5, regParam=0.01, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "              coldStartStrategy=\"drop\")\n",
    "    model = als.fit(training)\n",
    "    model.write().overwrite().save(\"als.model\")\n",
    "    #https://stackoverflow.com/a/53931249\n",
    "\n",
    "    #SPARK CORROMPE IL CSV -> se hadoop non sta girando. ha un po' di senso ma non troppo\n",
    "else:\n",
    "    model = ALSModel.load(\"als.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root-mean-square error = 0.16459797123073772\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model by computing the RMSE on the test data\n",
    "predictions = model.transform(test).na.fill(0)\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",\n",
    "                                predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root-mean-square error = \" + str(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to export/use the model?\n",
    "    model.itemFactors.collect()\n",
    "    model.userFactors.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(movieId=148, rating=0.7, timestamp=1247893752, userId=249376, prediction=0.5018646121025085)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 249376\n",
    "predictions.filter(predictions.userId==user_id).sort(F.col(\"prediction\")).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
